{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae78e63c"
      },
      "source": [
        "#Exercise\n",
        "This is a dataset related to how much money a person can get from a mortgage on his or her home. This dataset includes the following features:\n",
        "* Gender: Gender of the borrower (including two values 'F' and 'M')\n",
        "* Age: Age of the customer applying for a loan (including positive integer values)\n",
        "* Income (USD): Customer's income in USD (value is a positive number)\n",
        "* Income Stability: The level of customer's income stability (including three values of Low and High)\n",
        "* Property Age: Life expectancy of the house in days (including positive integer values)\n",
        "* Property Location: Location of the house (including 'Rural', 'Urban', and 'Semi-Urban')\n",
        "* Property Price: The value of the house in USD (including positive real values)\n",
        "* Loan Sanction Amount (USD): Amount that customers can borrow in USD (target value)\n",
        "\n",
        "Based on practice sample #1, proceed:\n",
        "1. Read data\n",
        "2. Visualize some information of data\n",
        "3. Normalize Data to train linear regression model\n",
        "4. Train linear regression model and show the model's intercepts, coeficients\n",
        "5. Learn on sklearn how to use Ridge, Lasso, and ElasticNet compare the error of all 3 algorithms with Linear Regression (https://scikit-learn.org/stable/index.html)\n",
        "6. Let's try Polynomial of order 2 to compare the previous results. What will the result be if we choose the n order too high?\n",
        "\n",
        "\n",
        "**Submission Link**: https://forms.gle/uKAq34QrbwTcbs5Z9 (Submit your .ipynb file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "mYV5QYEaZD5N"
      },
      "outputs": [],
      "source": [
        "# mount data from google drive to colab\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "#import library\n",
        "import pandas as pd # pandas\n",
        "import numpy as np # numpy\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWey3cHTb43g"
      },
      "source": [
        "# Prepare and Analyze Data\n",
        "\n",
        "1. Load Dataset\n",
        "2. Analyze Dataset\n",
        "3. Preprocess data (type, null, missing, ...)\n",
        "4. Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QJmB36JjdyC"
      },
      "source": [
        "## Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b6967e88"
      },
      "outputs": [],
      "source": [
        "# read data using Pandas DataFrame\n",
        "def read_dataset(path):\n",
        "    # Todo: read_csv from a path and return a DataFrame\n",
        "    df = pd.read_csv(path)\n",
        "    display(df.head())\n",
        "    display(df.describe())\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bRSvpuUCfpDr"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'final_house_loan'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal_house_loan\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Path to your file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#ToDo: Show histogram of dataframe\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[10], line 4\u001b[0m, in \u001b[0;36mread_dataset\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mread_dataset\u001b[39m(path):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Todo: read_csv from a path and return a DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     display(df\u001b[38;5;241m.\u001b[39mhead())\n\u001b[0;32m      6\u001b[0m     display(df\u001b[38;5;241m.\u001b[39mdescribe())\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python313\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'final_house_loan'"
          ]
        }
      ],
      "source": [
        "path = \"final_house_loan\" # Path to your file\n",
        "\n",
        "df = read_dataset(path)\n",
        "#ToDo: Show histogram of dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLqfm42rjgO2"
      },
      "source": [
        "## Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZFahON289oe"
      },
      "outputs": [],
      "source": [
        "# Data analysis\n",
        "# Todo: analyze your data here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWQ3y3T2f32N"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f647dba"
      },
      "outputs": [],
      "source": [
        "def preprocessing_data(df):\n",
        "    # --- (Optional) Drop null datapoints or fill missing data\n",
        "    # Keep your data the same if you dont want to customize it\n",
        "    df =\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9KKiP3yd3m8t"
      },
      "outputs": [],
      "source": [
        "df = preprocessing_data(df.copy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEu9oydOjZem"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee4UO0d_2-ED"
      },
      "outputs": [],
      "source": [
        "def normalize_data(df):\n",
        "    df = # Todo: normalize data into numerical data\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AmepvqLbknvO"
      },
      "outputs": [],
      "source": [
        "# Heatmap\n",
        "import seaborn as sns\n",
        "\n",
        "df = normalize_data(df.copy())\n",
        "sns.heatmap(df.corr()) # Show heatmap after normalized data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzgR-i-gE1hc"
      },
      "source": [
        "# Apply machine learning model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ppt3beFBjnID"
      },
      "source": [
        "## Train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dodR58Ha3wgf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBo9kxbmSZiF"
      },
      "outputs": [],
      "source": [
        "def prepare_X_y(df):\n",
        "    # Split data into X and y. Return two dataframes\n",
        "    X = # Todo: Select features\n",
        "    y = # Todo: Select label\n",
        "    return X, y\n",
        "\n",
        "X, y = prepare_X_y(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oanMcOPgScf7"
      },
      "outputs": [],
      "source": [
        "def split_train_test(X, y, train_size=0.7):\n",
        "    trainX, testX ,trainY, testY = # Use sklearn train_test_split to split X and y into 2 sets: train set and test set. With train_size is the proportion of train_set and fix the random_state with a number\n",
        "    print('Training:' + str(trainX.shape))\n",
        "    print('Test:' + str(testX.shape))\n",
        "\n",
        "    return trainX, testX ,trainY, testY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFvHM8hA4vlr"
      },
      "outputs": [],
      "source": [
        "TRAIN_SIZE = 0.7\n",
        "\n",
        "trainX, testX ,trainY, testY = split_train_test(X, y, train_size=TRAIN_SIZE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xECUjRuFy2e"
      },
      "source": [
        "## Basic Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aIK-of7E6Wv"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def build_linear_model(X, y):\n",
        "    model = # Todo: use sklearn model and config your parameters\n",
        "    # Todo: fit your model with X, y\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_linear_model(trainX, trainY)\n",
        "# Compare on training dataset\n",
        "pred = model.predict(trainX)\n",
        "print(\"mean absolute error of linear model on train set \", mean_absolute_error(y_pred=pred, y_true=trainY) )\n",
        "pred = model.predict(testX)\n",
        "print(\"mean absolute error of linear model on test set \", mean_absolute_error(y_pred=pred, y_true=testY) )\n",
        "\n",
        "print(model.coef_) # print coefficient\n",
        "print()\n",
        "print(model.intercept_) # print intercept_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snbiK5iHFJb_"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def build_lasso_model(X, y):\n",
        "    model = # Todo: use sklearn model and config your parameters\n",
        "    # Todo: fit your model with X, y\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_lasso_model(trainX, trainY)\n",
        "# Compare on training dataset\n",
        "pred = model.predict(trainX)\n",
        "print(\"mean absolute error of linear model on train set \", mean_absolute_error(y_pred=pred, y_true=trainY) )\n",
        "pred = model.predict(testX)\n",
        "print(\"mean absolute error of linear model on test set \", mean_absolute_error(y_pred=pred, y_true=testY) )\n",
        "\n",
        "print(model.coef_) # print coefficient\n",
        "print()\n",
        "print(model.intercept_) # print intercept_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_xH5lqi35WAJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def build_ridge_model(X, y):\n",
        "    model = # Todo: use sklearn model and config your parameters\n",
        "    # Todo: fit your model with X, y\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_ridge_model(trainX, trainY)\n",
        "# Compare on training dataset\n",
        "pred = model.predict(trainX)\n",
        "print(\"mean absolute error of linear model on train set \", mean_absolute_error(y_pred=pred, y_true=trainY) )\n",
        "pred = model.predict(testX)\n",
        "print(\"mean absolute error of linear model on test set \", mean_absolute_error(y_pred=pred, y_true=testY) )\n",
        "\n",
        "print(model.coef_) # print coefficient\n",
        "print()\n",
        "print(model.intercept_) # print intercept_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOZ7NPAG53rg"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "def build_elastic_model(X, y):\n",
        "    model = # Todo: use sklearn model and config your parameters\n",
        "    # Todo: fit your model with X, y\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_elastic_model(trainX, trainY)\n",
        "# Compare on training dataset\n",
        "pred = model.predict(trainX)\n",
        "print(\"mean absolute error of linear model on train set \", mean_absolute_error(y_pred=pred, y_true=trainY) )\n",
        "pred = model.predict(testX)\n",
        "print(\"mean absolute error of linear model on test set \", mean_absolute_error(y_pred=pred, y_true=testY) )\n",
        "\n",
        "print(model.coef_) # print coefficient\n",
        "print()\n",
        "print(model.intercept_) # print intercept_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SDs25IOFoBw"
      },
      "source": [
        "## Polynomial Transform"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkeldd8AF_Ju"
      },
      "source": [
        "When the data feature does not conform to a linear function, a linear regression cannot be applied directly to the original data. Then, there are many possibilities that the data feature conforms to the polynomial function. Scikit-Learn supports converting data features to polynomials through ``PolynomialFeatures``.\n",
        "\n",
        "$$\n",
        "y = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots\n",
        "$$\n",
        "\n",
        "The formula above uses the transformation of the value $x$ from one dimension to the other, with the aim of being able to use linear regression to find complex relationships between $x$ and $y$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PXhjw_utFxzS"
      },
      "outputs": [],
      "source": [
        "#Linear Regression with Polynomial Transform\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "def build_pipeline(X, y):\n",
        "    poly_model = make_pipeline() # use make_pipeline to apply PolynomialFeatures and a Regression model train your dataset\n",
        "    poly_model.fit(X, y)\n",
        "\n",
        "    return poly_model\n",
        "# Compare on training dataset\n",
        "poly_pred = poly_model.predict(trainX)\n",
        "print(\"mean absolute error of linear model (with poly transform) on train set \", mean_absolute_error(y_pred=poly_pred, y_true=trainY) )\n",
        "\n",
        "poly_pred = poly_model.predict(testX)\n",
        "print(\"mean absolute error of linear model (with poly transform) on test set \", mean_absolute_error(y_pred=poly_pred, y_true=testY))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
